{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 13:06:32.028427: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 13:06:41.395179: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 13:06:41.448644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 13:06:41.449370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 13:06:41.452077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 13:06:41.452668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 13:06:41.453035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 13:06:52.510647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 13:06:52.511271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 13:06:52.511291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 13:06:52.511562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 13:06:52.511736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1812 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 3GB, pci bus id: 0000:1c:00.0, compute capability: 6.1\n",
      "2023-05-09 13:06:53.724057: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 460800000 exceeds 10% of free system memory.\n",
      "2023-05-09 13:06:54.166692: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 460800000 exceeds 10% of free system memory.\n",
      "2023-05-09 13:06:58.426556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-09 13:07:02.822835: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fe6d4008250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-09 13:07:02.822946: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 3GB, Compute Capability 6.1\n",
      "2023-05-09 13:07:02.845043: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-09 13:07:03.866872: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 載入資料並進行前處理\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# 定義模型\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 設定 KFold 參數\n",
    "num_folds = 4\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# 初始化\n",
    "all_scores = []\n",
    "\n",
    "# 進行 KFold 交叉驗證\n",
    "for fold_index, (train_indices, val_indices) in enumerate(kfold.split(x_train)):\n",
    "    # 建立模型\n",
    "    model = create_model()\n",
    "\n",
    "    # 取得 KFold 中的訓練資料和驗證資料\n",
    "    x_train_fold = x_train[train_indices]\n",
    "    y_train_fold = y_train[train_indices]\n",
    "    x_val_fold = x_train[val_indices]\n",
    "    y_val_fold = y_train[val_indices]\n",
    "\n",
    "    # 訓練模型\n",
    "    model.fit(x_train_fold, y_train_fold, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # 評估模型\n",
    "    scores = model.evaluate(x_val_fold, y_val_fold, verbose=0)\n",
    "    print(\"Fold #{}: {}%\".format(fold_index, scores[1]*100))\n",
    "\n",
    "    # 將評估結果加入 all_scores\n",
    "    all_scores.append(scores[1])\n",
    "\n",
    "# 計算平均 accuracy\n",
    "mean_accuracy = np.mean(all_scores)\n",
    "print(\"Mean Accuracy: {}%\".format(mean_accuracy*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
